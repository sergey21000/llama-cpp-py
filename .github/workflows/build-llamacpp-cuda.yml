name: Build llama.cpp CUDA (linux x64)

on:
  workflow_dispatch:

permissions:
  contents: write

env:
  CMAKE_ARGS: >
    -DGGML_BACKEND_DL=ON
    -DGGML_NATIVE=OFF
    -DGGML_CPU=OFF
    -DGGML_CUDA=ON
    -DLLAMA_BUILD_EXAMPLES=OFF
    -DLLAMA_BUILD_TESTS=OFF
    -DLLAMA_BUILD_TOOLS=ON
    -DLLAMA_BUILD_SERVER=ON
    -DGGML_RPC=ON

jobs:
  linux-cuda:
    runs-on: ubuntu-22.04

    strategy:
      matrix:
        cuda: ['12.4.1']

    steps:
      - name: Clean up disk space before build
        run: |
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /usr/local/lib/android
          sudo rm -rf /opt/ghc
          docker system prune -af || true

      - name: Checkout llama.cpp
        uses: actions/checkout@v6
        with:
          repository: ggml-org/llama.cpp
          ref: master
          fetch-depth: 0

      - name: ccache
        uses: ggml-org/ccache-action@v1.2.16
        with:
          key: linux-cuda-${{ matrix.cuda }}
          evict-old-files: 1d

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential libssl-dev

      - name: Install CUDA Toolkit
        uses: Jimver/cuda-toolkit@v0.2.16
        with:
          cuda: ${{ matrix.cuda }}

      - name: Build
        run: |
          cmake -B build \
            -DCMAKE_BUILD_TYPE=Release \
            -DCMAKE_INSTALL_RPATH='$ORIGIN' \
            -DCMAKE_BUILD_WITH_INSTALL_RPATH=ON \
            $CMAKE_ARGS
          cmake --build build --config Release -j $(nproc) --target ggml-cuda

      - name: Determine tag name
        id: tag
        uses: ./.github/actions/get-tag-name

      - name: Pack artifacts
        run: |
          mkdir -p dist
          cp build/bin/libggml-cuda.so dist/
          tar -czvf llama-${{ steps.tag.outputs.name }}-bin-ubuntu-cuda-${{ matrix.cuda }}-x64.tar.gz \
            --transform "s,^,llama-${{ steps.tag.outputs.name }}/," -C dist .

      - name: Upload artifacts
        uses: actions/upload-artifact@v6
        with:
          name: llama-bin-ubuntu-cuda-${{ matrix.cuda }}-x64
          path: llama-${{ steps.tag.outputs.name }}-bin-ubuntu-cuda-${{ matrix.cuda }}-x64.tar.gz